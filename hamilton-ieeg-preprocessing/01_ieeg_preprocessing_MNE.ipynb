{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dce6adc",
   "metadata": {},
   "source": [
    "# Preprocessing intracranial EEG using MNE-python\n",
    "\n",
    "\n",
    "*NeuroHackademy 2023*  \n",
    "[Liberty Hamilton, PhD](https://slhs.utexas.edu/research/hamilton-lab)  \n",
    "Assistant Professor, Department of Speech, Language, and Hearing Sciences and  \n",
    "Department of Neurology  \n",
    "The University of Texas at Austin \n",
    "\n",
    "## Part 1: Loading, Plotting, and Referencing\n",
    "This notebook will show you how to preprocess intracranial EEG using MNE-python. This uses a freely available iEEG dataset on audiovisual movie watching from [Julia Berezutskaya, available on OpenNeuro.org](https://openneuro.org/datasets/ds003688/versions/1.0.7/metadata). This notebook covers the basics of how to look at iEEG data, interpret effects of referencing, and inspect data quality. In part 2, we will cover high gamma extraction and referencing. The method of high gamma extraction is identical to that used in [Hamilton et al. 2018](https://doi.org/10.1016/j.cub.2018.04.033) and [Hamilton et al. 2021](https://doi.org/10.1016/j.cell.2021.07.019).\n",
    "\n",
    "## Python libraries used in this tutorial\n",
    "\n",
    "* matplotlib\n",
    "* mne_bids\n",
    "* [MNE-python](https://mne.tools/stable/install/index.html)\n",
    "* numpy\n",
    "* pandas\n",
    "* pybids\n",
    "\n",
    "## What you will do in this tutorial\n",
    "\n",
    "* Load an iEEG dataset in MNE-python\n",
    "* Compare iEEG dataset with BIDs metadata vs. without so you know what to do if you encounter data without this info\n",
    "* Plot the power spectrum of the data to check for bad channels and compare channel types\n",
    "* Re-reference the data according to different reference schemes\n",
    "\n",
    "### and in part 2! ([`02_ieeg_preprocessing_MNE_epochs.ipynb`](02_ieeg_preprocessing_MNE_epochs.ipynb))\n",
    "* Compute the high gamma analytic amplitude of the signal\n",
    "* Plot evoked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb884ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import mne\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from mne_bids import read_raw_bids, print_dir_tree\n",
    "from mne_bids.path import get_bids_path_from_fname\n",
    "from bids import BIDSLayout\n",
    "from ecog_preproc_utils import transformData\n",
    "import bids \n",
    "import re  # regex for comparing channel names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227f2b5d",
   "metadata": {},
   "source": [
    "## Download BIDS iEEG dataset\n",
    "\n",
    "Here we will download an example iEEG dataset from [Berezutskaya et al.  Open multimodal iEEG-fMRI dataset from naturalistic stimulation with a short audiovisual film](https://openneuro.org/datasets/ds003688/versions/1.0.7/metadata). For this tutorial we will use data from `sub-06`, `iemu` data only, which has been downloaded to the jupyter hub. The whole dataset is rather large (15 GB), so if you prefer to download just this session you can do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3661b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the example participant's data that we will load for the tutorial,\n",
    "# but there are more options.\n",
    "subj = '06'\n",
    "sess = 'iemu'\n",
    "task = 'film'\n",
    "acq = 'clinical'\n",
    "run = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655a1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the data directory below to where your data are located. \n",
    "parent_dir = '/home/jovyan/shared/ds003688/'  # This is on the jupyter hub\n",
    "ieeg_dir = f'{parent_dir}/sub-{subj}/ses-{sess}/ieeg/'\n",
    "channel_path = f'{ieeg_dir}/sub-{subj}_ses-{sess}_task-{task}_acq-{acq}_run-{run}_channels.tsv'\n",
    "raw_path = f'{ieeg_dir}/sub-{subj}_ses-{sess}_task-{task}_acq-{acq}_run-{run}_ieeg.vhdr'\n",
    "\n",
    "bids_path = get_bids_path_from_fname(raw_path)\n",
    "base_name = os.path.basename(raw_path).split('.')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9faf41",
   "metadata": {},
   "source": [
    "## BIDS layout\n",
    "\n",
    "We can use `pybids` to show a little bit about the files in this BIDS dataset. We won't get as much into this, but if you'd like to try this tutorial on your own you may wish to delve into this more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953df68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = BIDSLayout(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d328249",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.get_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cb681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = layout.get()\n",
    "print(\"There are {} files in the layout.\".format(len(all_files)))\n",
    "print(\"\\nThe first 10 files are:\")\n",
    "all_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0587e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_dir_tree(parent_dir, max_depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0da51ef",
   "metadata": {},
   "source": [
    "## Let's load some iEEG data!\n",
    "\n",
    "First, we will choose the relevant subject, session, task, acquisition, and run. Note that if you wish to change these variables, you may need to download the data yourself.\n",
    "\n",
    "To show the capabilities of BIDS and contrast to when we don't use BIDS, we'll load the data in two ways. The data structure using BIDS will be called `raw`, the data structure without BIDS will be `raw_nobids`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4431118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data and extract parameters from BIDS files\n",
    "raw = read_raw_bids(bids_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f070387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data assuming we didn't have the BIDS structure in place\n",
    "raw_nobids = mne.io.read_raw_brainvision(raw_path, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f183f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the data into memory and print some information about it. The \n",
    "# info structure contains a lot of helpful metadata about number of channels,\n",
    "# sampling rate, data types, etc. It can also contain information about the\n",
    "# participant and date of acquisition, however, this dataset has been anonymized.\n",
    "raw.load_data()\n",
    "raw.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cad9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info['ch_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfb13c7",
   "metadata": {},
   "source": [
    "## Plot the raw data\n",
    "\n",
    "Let's first inspect the raw data to see how it looks, what type of information we have, and whether we can immediately see any bad channels or bad time segments that should be rejected. Typically this portion should be done interactively so you can scroll through the data using the arrow keys. \n",
    "\n",
    "We will compare and contrast the data loaded using MNE BIDS (`raw`) versus the data loaded without this information (`raw_nodbids`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcaa967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data, reject bad segments. Look for times where there\n",
    "# are spike wave discharges (epileptiform artifacts) or large\n",
    "# movement artifacts. Be selective, look out for blocks with a \n",
    "# ton of seizure activity\n",
    "raw.plot(scalings='auto', color=dict(eeg='b', ecog='b'), n_channels=64, block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee439c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data, reject bad segments. Look for times where there\n",
    "# are spike wave discharges (epileptiform artifacts) or large\n",
    "# movement artifacts. Be selective, look out for blocks with a \n",
    "# ton of seizure activity. This is when we don't have the nice\n",
    "# BIDS metadata automatically loaded in.\n",
    "raw_nobids.plot(scalings='auto', color=dict(eeg='b', ecog='b'), n_channels=64, block=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f25b19",
   "metadata": {},
   "source": [
    "## Plot the power spectrum\n",
    "\n",
    "Now we will plot the power spectrum of the signal to give us an idea of the signals we're getting. Bad channels (or channels that are not EEG/ECoG) will often have a very different power spectrum than the good channels. These will show up as highly outside the range of the other channels (either flat, or much higher/lower power)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197d0675",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.compute_psd().plot(picks='data', exclude=[]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19780bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to see other options we have for computing the power spectrum, \n",
    "# we can consult the help function\n",
    "raw.compute_psd?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f18c9dc",
   "metadata": {},
   "source": [
    "## Do the same without having loaded the metadata from BIDs\n",
    "\n",
    "Here we will see the data with bad channels included, and with all the channel types marked as EEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb9fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_nobids.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27232b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_nobids.compute_psd().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d6e07d",
   "metadata": {},
   "source": [
    "## Referencing\n",
    "\n",
    "Referencing or re-referencing your data should be done with some knowledge of your recording setup and what you wish to measure. You can read more about referencing [here (for EEG)](https://pressrelease.brainproducts.com/referencing/#:~:text=The%20reference%20influences%20the%20amplitude,affected%20by%20similar%20electrical%20activity.). Typically, experimenters will choose one of the following references:\n",
    "\n",
    "1. Based on a single electrode in white matter (or relatively \"quiet\" electrode far away from your signals of interest. \n",
    "2. Based on the average of all electrodes or a block of electrodes (CAR or Common Average Reference). Note that the CAR is *not* a good idea if all of your electrodes are within a single functional area, as you will likely subtract out more signal than noise. \n",
    "3. Bipolar referencing, in which pairs of adjacent electrodes are subtracted to calculate more local signals. This is a bit more complicated but allows you to work with data in a single region without the drawbacks of the CAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a4d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of single reference channel - this subtracts the signal from this channel\n",
    "# from all other channels (including itself), so the reference will appear as a flat\n",
    "# line after this step\n",
    "raw_ref = raw.copy()\n",
    "raw_ref.set_eeg_reference(ref_channels = ['P01'], )\n",
    "raw_ref.plot(scalings='auto', color=dict(eeg='b', ecog='b'), n_channels=64, block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3213ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of common average reference. The common average reference subtracts the average\n",
    "# signal across all *good* channels from every single channel. This is typically a good\n",
    "# choice for removing noise across all channels (for example, sometimes EMG from chewing,\n",
    "# some movement artifacts, electrical noise).\n",
    "raw_ref_car = raw.copy()\n",
    "raw_ref_car.set_eeg_reference(ref_channels = 'average')\n",
    "raw_ref_car.plot(scalings='auto', color=dict(eeg='b', ecog='b'), n_channels=64, block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea95cd07",
   "metadata": {},
   "source": [
    "## Bipolar reference\n",
    "\n",
    "Bipolar referencing is a bit trickier and is not fully implemented here. You need to use knowledge of the physical locations of the electrodes to properly create the bipolar montage. For example, in the image below, we would need to use the knowledge of how the electrodes are placed in order to create the appropriate pairs for the anode and cathode.\n",
    "\n",
    "![sub-06 electrode locations](sub-06_ses-iemu_acq-render_photo_ecog_left.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3230ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of bipolar reference. This would normally be done with some manual\n",
    "# intervention of the specific channel pairs. \n",
    "raw_ieeg = raw.copy()\n",
    "raw_ieeg.pick_types(ecog=True)\n",
    "ch_pairs = list(zip(raw_ieeg.info['ch_names'][:-1],\n",
    "                    raw_ieeg.info['ch_names'][1:]))\n",
    "\n",
    "# Make a list of channels for the anode and the cathode\n",
    "anode = []\n",
    "cathode = []\n",
    "# Only subtract channels with the same device name (these will be\n",
    "# close in space). This is still not ideal as we are probably\n",
    "# subtracting electrodes that are far away from one another in \n",
    "# space (for example, electrodes 8 and 9 on the grid picture\n",
    "# above should not be used for a bipolar reference)\n",
    "for pair in ch_pairs:\n",
    "    # get rid of the numbers in the ch_name\n",
    "    ch1_dev = re.sub(r'\\d+', '', pair[0]) \n",
    "    ch2_dev = re.sub(r'\\d+', '', pair[1]) \n",
    "    # if these are part of the same device, consider them for \n",
    "    # anode and cathode selection\n",
    "    if ch1_dev == ch2_dev:\n",
    "        anode.append(pair[0])\n",
    "        cathode.append(pair[1])\n",
    "\n",
    "# Apply the bipolar reference\n",
    "raw_ref_bip = mne.set_bipolar_reference(raw, anode=anode, cathode=cathode)\n",
    "raw_ref_bip.plot(scalings='auto', color=dict(eeg='b', ecog='b'), n_channels=64, block=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545256a0",
   "metadata": {},
   "source": [
    "## Want to plot some evoked data? \n",
    "\n",
    "Go to Part 2! [02_ieeg_preprocessing_MNE_epochs.ipynb](02_ieeg_preprocessing_MNE_epochs.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afc7e34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
